{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from IPython.display import display, clear_output\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "import itertools\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Филигранно распикливаем ([с возможной утечкой памяти:)](https://stackoverflow.com/questions/7395542/is-explicitly-closing-files-important))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_dict = pickle.load(open('data/chgk/players.pkl', 'rb'))\n",
    "results_dict = pickle.load(open('data/chgk/results.pkl', 'rb'))\n",
    "tournaments_dict = pickle.load(open('data/chgk/tournaments.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тренировочном наборе оставляем только турниры, у которых `dateStart` 2019, в тестовый набор - турниры, у которых `dateStart` 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтруем `results`, оставляем только те, где есть `mask` в ключах (без повопросных результатов обучать силу проблематично)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filtered_train = {}\n",
    "results_filtered_test = {}\n",
    "for k, res in results_dict.items():\n",
    "    t_res_new = []\n",
    "    for t_res in results_dict[k]:\n",
    "        if 'mask' in t_res.keys():\n",
    "            if t_res['mask'] is not None:\n",
    "                if 'X' not in t_res['mask'] and '?' not in t_res['mask']:\n",
    "                    t_res_new.append(t_res)\n",
    "    if t_res_new:\n",
    "        if tournaments_dict[k]['dateStart'].startswith('2019'):\n",
    "            results_filtered_train[k] = t_res_new\n",
    "        if tournaments_dict[k]['dateStart'].startswith('2020'):\n",
    "            results_filtered_test[k] = t_res_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также понадобится правильное число вопросов в каждом турнире, чтобы фильтровать результаты по длине маски\n",
    "(иначе получится так, что разные команды в рамках одного турнира ответили на разное количество вопросов, а значит не получится восстановить однозначное соответствие `команда`-`вопрос`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_question_count = {}\n",
    "\n",
    "for k, v in results_filtered_train.items():\n",
    "    tournament_question_count[k]= max([len(t_res['mask']) for t_res in v])\n",
    "    \n",
    "for k, v in results_filtered_test.items():\n",
    "    tournament_question_count[k]= max([len(t_res['mask']) for t_res in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filtered_train_len = {}\n",
    "results_filtered_test_len = {}\n",
    "train_players = set()\n",
    "for k, v in results_filtered_train.items():\n",
    "    t_res_ = []\n",
    "    for t_res in v:\n",
    "        if len(t_res['mask']) == tournament_question_count[k]:\n",
    "            train_players.update([m['player']['id'] for m in t_res['teamMembers']])\n",
    "            t_res_.append(t_res)\n",
    "    results_filtered_train_len[k] = t_res_\n",
    "\n",
    "for k, v in results_filtered_test.items():\n",
    "    t_res_ = []\n",
    "    for t_res in v:\n",
    "        if len(t_res['mask']) == tournament_question_count[k]:\n",
    "            t_res_.append(t_res)\n",
    "    results_filtered_test_len[k] = t_res_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делая наивное предположение что если команда ответила на вопрос, то каждый игрок в этой команде ответил на вопрос, собираем большую таблицу взаимодействий `игрок-вопрос-[ответил/не ответил]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_df = pd.DataFrame(columns=['pid', 'qid', 'tournament', 'tid', 'res'])\n",
    "\n",
    "pid = []\n",
    "qid = []\n",
    "res = []\n",
    "tournament = []\n",
    "tid = []\n",
    "for k, v in results_filtered_train_len.items():\n",
    "    for t_res in v:\n",
    "        members = [m['player']['id'] for m in t_res['teamMembers']]\n",
    "        t_pid = list(itertools.chain.from_iterable(itertools.repeat(m, tournament_question_count[k]) for m in members))\n",
    "        pid.extend(t_pid)\n",
    "        t_qid = [f'{k}_{i}' for i in range(tournament_question_count[k])] * len(members)\n",
    "        qid.extend(t_qid)\n",
    "        tid.extend([t_res['team']['id']] * len(t_qid))\n",
    "        tournament.extend([k] * len(t_qid))\n",
    "        res.extend(list(map(int, t_res['mask'])) * len(members))\n",
    "\n",
    "pq_df['pid'] = np.int32(pid)\n",
    "pq_df['qid'] = qid\n",
    "pq_df['tournament'] = tournament\n",
    "pq_df['tid'] = tid\n",
    "pq_df['res'] = np.int8(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарь `tournament_results_train` и `tournament_results_t_test` нужен для тестирования полученных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_results_train = {}\n",
    "for tourn_id, t_res in results_filtered_train_len.items():\n",
    "    tids, names, positions, qtotals, members = [], [], [], [], []\n",
    "    for team in t_res:\n",
    "        members.append([m['player']['id'] for m in team['teamMembers']])\n",
    "        tids.append(team['team']['id'])\n",
    "        names.append(team['team']['name'])\n",
    "        positions.append(team['position'])\n",
    "        qtotals.append(team['questionsTotal'])\n",
    "        \n",
    "    tournament_results_train[tourn_id] = pd.DataFrame(\n",
    "        {\n",
    "        'tid': tids,\n",
    "        'name': names,\n",
    "        'position': positions,\n",
    "        'qtotal': qtotals,\n",
    "        'members': members\n",
    "        }\n",
    "    ).sort_values(by='position')\n",
    "    \n",
    "\n",
    "tournament_results_test = {}\n",
    "for tourn_id, t_res in results_filtered_test_len.items():\n",
    "    tids, names, positions, qtotals, members = [], [], [], [], []\n",
    "    for team in t_res:\n",
    "        t_members = []\n",
    "        for m in team['teamMembers']:\n",
    "            if m['player']['id'] in train_players:\n",
    "                t_members.append(m['player']['id'])\n",
    "        if t_members:\n",
    "            members.append(t_members)\n",
    "            tids.append(team['team']['id'])\n",
    "            names.append(team['team']['name'])\n",
    "            positions.append(team['position'])\n",
    "            qtotals.append(team['questionsTotal'])\n",
    "    tournament_results_test[tourn_id] = pd.DataFrame(\n",
    "        {\n",
    "        'tid': tids,\n",
    "        'name': names,\n",
    "        'position': positions,\n",
    "        'qtotal': qtotals,\n",
    "        'members': members\n",
    "        }\n",
    "    ).sort_values(by='position')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предположения:\n",
    "\n",
    "- игрок ответил на вопрос == команда в которой был игрок ответила на вопрос\n",
    "\n",
    "- вероятность того, что игрок ответит на вопрос зависит от сложности вопроса и умений игрока, и никак не зависит от того в какой он команде\n",
    "\n",
    "__Тогда__:\n",
    "\n",
    "Событие $A_{pq}$ == p-игрок ответил на q-ый вопрос\n",
    "\n",
    "В таком случае\n",
    "\n",
    "$P(A_{pq}) = \\sigma(skill_p + difficult_q)$\n",
    "\n",
    "Таким образом, из повопросного датасета можно выучить `skill_p` и `difficult_q` (просто записав лолгосс и минимизировать его градиентным спуском)\n",
    "\n",
    "Однако, очень удобно (для того чтобы использовать библиотечные солверы и прочие радости) кодировать $A_{pq}$ с помощью `OneHotEncoding`. В таком случае, \n",
    "если $x_i$ = `[0, 0, ..., [1 на месте p], 0, 0, ... [1 на месте q]]`, умножить его скалярно на вектор `np.concat([skills, difficults])` это то же самое, что сложить `skill_p + difficult_q`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a18570724/.local/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/a18570724/.local/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=10, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(categorical_features=[0, 1], sparse=True, dtype=np.int8)\n",
    "encoder.fit(pq_df)\n",
    "pq_df_oh = encoder.transform(pq_df[['pid', 'qid']])\n",
    "clf = LogisticRegression(solver='lbfgs', n_jobs=10)\n",
    "clf.fit(pq_df_oh, pq_df['res'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим рейтинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tournaments_rating_n_corrs(encoder, player_q_df, weights, t_results_test):\n",
    "    t_results_test_ = t_results_test.copy()\n",
    "    feature_names = np.array([fname.replace('.0','') for fname in encoder.get_feature_names(pq_df.columns[:2])])\n",
    "    players = feature_names[[fname.startswith('pid') for fname in feature_names]]\n",
    "    players = np.array(list(map(lambda x: np.int32(x.replace('pid_','')), players)))\n",
    "    players_scores = pd.DataFrame({'player_id': players, 'score': weights[:len(players)]}).set_index('player_id')\n",
    "    corrs_spearman = []\n",
    "    corrs_kendall = []\n",
    "    for t_id, t_result in t_results_test_.items():\n",
    "        t_result['predicted_score'] = t_result['members'].apply(lambda x: players_scores.loc[x]['score'].mean())\n",
    "        corrs_spearman.append(np.abs(t_result[['position', 'predicted_score']].corr(method='spearman')['position']['predicted_score']))\n",
    "        corrs_kendall.append(np.abs(t_result[['position', 'predicted_score']].corr(method='kendall')['position']['predicted_score']))\n",
    "    return t_results_test_, np.mean(corrs_spearman), np.mean(corrs_kendall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_results_pred, spearman, kendall = get_tournaments_rating_n_corrs(encoder, pq_df, clf.coef_[0], tournament_results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744970560215479\n",
      "0.5876959484196173\n"
     ]
    }
   ],
   "source": [
    "print(spearman)\n",
    "print(kendall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM - схема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку ЧГК - командная игра, кажется не слишком разумным что если игрок взял вопрос вместе с какой-то командой, то он сам ответил на этот вопрос. Нужно как-то учитывать выступление одного и того же игрока в разных командах, другими словами, как и сказано в задании, переменные “игрок X ответил на вопрос Y” при условии данных должны стать зависимыми для игроков одной и той же команды\n",
    "\n",
    "__Предлагаемая EM-схема__:\n",
    "\n",
    "Будем использовать результат игрока $p$ на вопросе $q$ в качестве скрытой переменной (`res_pq`). Тогда\n",
    "\n",
    "* __E-шаг__:\n",
    "\n",
    "На $E$-шаге оцениваем мат-ожидание выбранной скрытой переменной. Предположим, что если хотя бы один игрок ответил на вопрос верно, то команда ответит на вопрос верно.\n",
    "\n",
    "Тогда\n",
    "\n",
    "$$\\mathop{\\mathbb{E}}(res_{pq}) = {p(A_{pq} | A_{tq})} = \\frac{\\sigma(skill_p + difficult_q)}{1 - \\prod_{p \\in t}(1 - \\sigma(skill_p + difficult_q))}$$, \n",
    "если команда ответила на вопрос, и $0$, если не ответила\n",
    "\n",
    "\n",
    "* __M-шаг__:\n",
    "\n",
    "На $M$-шаге просто учим логистическую регрессию на оцененные матожидания (правда я так и не понял как модель из `sklearn` заставить минимизировать лосс с мягкими метками, поэтому в качестве \"обучения логистической регрессии\" просто будем делать несколько шагов в сторону градиента правдоподобия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X, weights):\n",
    "    return 1 / (1 + np.exp(-X.dot(weights)))\n",
    "\n",
    "def log_likelihood(expectations, pq_df_oh, weights):\n",
    "    sigma = sigmoid(pq_df_oh, weights)\n",
    "    return np.sum(expectations * np.log(sigma) + (1 - expectations) * np.log(1 - sigma))\n",
    "    \n",
    "def weights_gradient(weights, expectations, pq_df_oh):\n",
    "    return (csr_matrix(expectations - sigmoid(pq_df_oh, weights)).dot(pq_df_oh)).toarray()[0] / np.array((pq_df_oh != 0).sum(axis=0)).ravel()\n",
    "\n",
    "def Expectation(weights, pq_df, pq_df_oh):\n",
    "    pq_df_ = pq_df.copy()\n",
    "    sigma = sigmoid(pq_df_oh, weights)\n",
    "    pq_df_['sigma'] = sigma\n",
    "    pq_df_['one_sigma'] = 1 - sigma\n",
    "    prods_series = 1 - pq_df_.groupby(['tournament', 'tid', 'qid'])['one_sigma'].prod().rename('prod')\n",
    "    pq_df_ = pq_df_.merge(prods_series, on=['tournament', 'tid', 'qid'])\n",
    "    expectations = (pq_df_['sigma'] / (pq_df_['prod'])).values\n",
    "    expectations[pq_df_['res'] == 0] = 0    \n",
    "    return expectations\n",
    "\n",
    "def Maximization(expectations, pq_df_oh, weights):\n",
    "    weights_ = weights\n",
    "    for i in range(30):\n",
    "        weights_ += 1.5 * weights_gradient(weights_, expectations, pq_df_oh)\n",
    "    return weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>log_ll</th>\n",
       "      <th>Kendall_corr</th>\n",
       "      <th>Spearman_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.570627</td>\n",
       "      <td>0.581917</td>\n",
       "      <td>0.736725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.421400</td>\n",
       "      <td>0.590454</td>\n",
       "      <td>0.746539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.355291</td>\n",
       "      <td>0.589807</td>\n",
       "      <td>0.745936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.331647</td>\n",
       "      <td>0.586606</td>\n",
       "      <td>0.742638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.323244</td>\n",
       "      <td>0.585941</td>\n",
       "      <td>0.741234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.320168</td>\n",
       "      <td>0.584214</td>\n",
       "      <td>0.739710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.319000</td>\n",
       "      <td>0.583554</td>\n",
       "      <td>0.738823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.318539</td>\n",
       "      <td>0.583433</td>\n",
       "      <td>0.738911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.318352</td>\n",
       "      <td>0.583373</td>\n",
       "      <td>0.738978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.318276</td>\n",
       "      <td>0.583314</td>\n",
       "      <td>0.738720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iter    log_ll  Kendall_corr  Spearman_corr\n",
       "0    1 -0.570627      0.581917       0.736725\n",
       "1    2 -0.421400      0.590454       0.746539\n",
       "2    3 -0.355291      0.589807       0.745936\n",
       "3    4 -0.331647      0.586606       0.742638\n",
       "4    5 -0.323244      0.585941       0.741234\n",
       "5    6 -0.320168      0.584214       0.739710\n",
       "6    7 -0.319000      0.583554       0.738823\n",
       "7    8 -0.318539      0.583433       0.738911\n",
       "8    9 -0.318352      0.583373       0.738978\n",
       "9   10 -0.318276      0.583314       0.738720"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = np.random.rand(pq_df_oh.shape[1])\n",
    "em_df = pd.DataFrame(columns=['iter', 'log_ll', 'Kendall_corr', 'Spearman_corr'])\n",
    "for i in range(10):\n",
    "    expectations = Expectation(weights, pq_df, pq_df_oh)\n",
    "    weights = Maximization(expectations, pq_df_oh, weights)\n",
    "    rating, corr_spearman, corr_kendall = get_tournaments_rating_n_corrs(encoder, pq_df, weights, tournament_results_test)\n",
    "    em_df = em_df.append(\n",
    "       pd.DataFrame(\n",
    "        {\n",
    "        'iter': [i + 1],\n",
    "        'log_ll': [log_likelihood(expectations, pq_df_oh, weights) / pq_df_oh.shape[0]],\n",
    "        'Kendall_corr': [corr_kendall],\n",
    "        'Spearman_corr' : [corr_spearman]\n",
    "    }), ignore_index=True)\n",
    "    clear_output()\n",
    "    display(em_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рейтинг лист турниров по сложности вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
