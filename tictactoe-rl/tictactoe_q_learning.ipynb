{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from tictactoe_env import TicTacToe\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer:\n",
    "    def strategy(self, state):\n",
    "        possible_steps = state[1]\n",
    "        return possible_steps[np.random.randint(possible_steps.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeGame:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def run_episode(self, player_x, player_o, return_history=False):\n",
    "        state, _, is_done, _ = self.env.reset()\n",
    "        states_x, states_o = [], []\n",
    "        rewards_x, rewards_o = [], []\n",
    "        players = [player_x, player_o]\n",
    "        cur_player = 0\n",
    "        while not is_done:\n",
    "            step = players[cur_player].strategy(state)\n",
    "            state, reward, is_done, _ = self.env.step(step)\n",
    "            if cur_player == 0:\n",
    "                rewards_x.append(reward)\n",
    "                states_x.append(state)\n",
    "            else:\n",
    "                rewards_o.append(-reward)\n",
    "                states_o.append(state)\n",
    "            cur_player = (cur_player + 1) % 2\n",
    "        if (len(rewards_x) > len(rewards_o)):\n",
    "            if (rewards_x[-1] == 1):\n",
    "                rewards_o.append(-1)\n",
    "            else:\n",
    "                rewards_o.append(0)\n",
    "        if (rewards_o[-1] == 1):\n",
    "            rewards_x[-1] = -1\n",
    "        if return_history:\n",
    "            return (states_x, rewards_x), (states_o, rewards_o)\n",
    "        return rewards_x[-1], rewards_o[-1]\n",
    "\n",
    "    def check_mean_reward(self, player_x, player_o, n_iter):\n",
    "        rewards_x = []\n",
    "        for _ in tqdm(range(n_iter)):\n",
    "            reward_x, _ = self.run_episode(player_x, player_o)\n",
    "            rewards_x.append(reward_x)\n",
    "        return np.mean(rewards_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe()\n",
    "game = TicTacToeGame(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, -1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_x = RandomPlayer()\n",
    "player_o = RandomPlayer()\n",
    "\n",
    "game.run_episode(player_x, player_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf59791cdf045d893670ff8e2e2cf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2974"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.check_mean_reward(player_x, player_o, n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningPlayer:\n",
    "    def __init__(self, eps, alpha, gamma, n_rows=3, n_cols=3):\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.q_table = defaultdict(lambda: np.zeros(n_rows * n_cols))\n",
    "        self.actions = list(product(range(n_rows), range(n_cols)))\n",
    "        self.set_training()\n",
    "    \n",
    "    def set_training(self):\n",
    "        self.training = True\n",
    "\n",
    "    def set_evaluating(self):\n",
    "        self.training = False\n",
    "\n",
    "    def update_q(self):\n",
    "        pass\n",
    "\n",
    "    def strategy(self, state):\n",
    "        state_hash = state[0]\n",
    "        coin = np.random.rand()\n",
    "        greedy_action = self.greedy_step(state_hash)\n",
    "        random_action = self.random_step()\n",
    "        if self.training:\n",
    "            coin = np.random.rand() < self.eps\n",
    "            if coin:\n",
    "                action = random_action\n",
    "            else:\n",
    "                action = greedy_action\n",
    "        else:\n",
    "            action = greedy_action\n",
    "        return action\n",
    "    \n",
    "    def greedy_step(self, state_hash):\n",
    "        return self.actions[self.q_table[state_hash].argmax()]\n",
    "    \n",
    "    def random_step(self):\n",
    "        return self.actions[np.random.randint(0, len(self.actions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplayer = QLearningPlayer(1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb046ae06292475faae641f925a74ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-4.63266"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.check_mean_reward(qplayer, qplayer, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10, 0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.run_episode(qplayer, qplayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a96679fb6303d6bfe882256a806ccdfeeac76400b462e2d8dedd73c503063ab7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('base_ml_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
